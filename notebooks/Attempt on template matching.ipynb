{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load(r\"..\\data\\raw\\fashion_train.npy\")\n",
    "data_img = [np.reshape(image[:784],(28,28)) for image in data_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the template matching with the averaged out templates for each category.\n",
    "Results are surprisingly good, given that the model is pretty straightforward in the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_main(mean_conf_matrix):\n",
    "    TP = np.diag(mean_conf_matrix)\n",
    "    FP = np.sum(mean_conf_matrix,axis=0)-TP\n",
    "    FN = np.sum(mean_conf_matrix,axis=1)-TP\n",
    "    accuracy = sum(TP)/sum(TP+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = 2*((precision*recall)/(precision+recall))\n",
    "    return [accuracy, precision, recall, F1]\n",
    "    \n",
    "# get_scores(mean_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "def get_col_name(row):    \n",
    "    b = (results_df.loc[row.name] == row['Template_score'])\n",
    "    return b.index[b.argmax()]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(data_raw)\n",
    "collect = []\n",
    "all_scores = []\n",
    "score_frame = pd.DataFrame([[data_raw[i,-1]]+[None]*5 for i in range(len(data_raw))])\n",
    "for i,(train_index, test_index) in enumerate(kf.split(data_raw)):\n",
    "    \n",
    "    print(f\"Fold {i}\")\n",
    "    \n",
    "    clothes = data_raw[train_index]\n",
    "    test_clothes = data_raw[test_index]\n",
    "    mean_clothes = [np.mean(clothes[clothes[:,-1]==x],axis=0) for x in range(5)]\n",
    "\n",
    "    test_results = pd.DataFrame(test_index)\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(mean_clothes)-1,-1,-1):\n",
    "        results = np.sqrt(np.sum(np.square((test_clothes-mean_clothes[i])),axis=1))\n",
    "        results_df.insert(0,i,pd.Series(results).values,allow_duplicates=True)\n",
    "        score_frame.iloc[test_index,i+1] = pd.Series(results).values\n",
    "\n",
    "    test_results['Actual_score'] = test_clothes[:,-1]\n",
    "    test_results.insert(2,\"Template_score\",results_df.min(axis = 1))\n",
    "    test_results['Template_score'] = test_results.apply(get_col_name, axis=1)\n",
    "                 \n",
    "    y_test = test_results['Actual_score']\n",
    "    y_pred = test_results['Template_score']\n",
    "    # print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    # print('Classification Report:\\n',classification_report(y_test, y_pred))\n",
    "    fold_scores = get_scores_main(confusion_matrix(y_test, y_pred))\n",
    "    # fold_scores +=\n",
    "    all_scores.append(fold_scores)\n",
    "    collect.append(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>786.163332</td>\n",
       "      <td>1893.617989</td>\n",
       "      <td>1656.606032</td>\n",
       "      <td>1508.050258</td>\n",
       "      <td>1265.243842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2036.162052</td>\n",
       "      <td>1216.147297</td>\n",
       "      <td>2521.655699</td>\n",
       "      <td>1644.656337</td>\n",
       "      <td>2072.8969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>948.560884</td>\n",
       "      <td>2171.532519</td>\n",
       "      <td>1861.113602</td>\n",
       "      <td>1777.445263</td>\n",
       "      <td>1569.230653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1522.75006</td>\n",
       "      <td>1475.920741</td>\n",
       "      <td>2057.235609</td>\n",
       "      <td>1309.609253</td>\n",
       "      <td>1591.616548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1548.300035</td>\n",
       "      <td>2092.940959</td>\n",
       "      <td>1342.575013</td>\n",
       "      <td>1792.842291</td>\n",
       "      <td>1041.100386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4</td>\n",
       "      <td>1552.679681</td>\n",
       "      <td>2298.016194</td>\n",
       "      <td>2018.83842</td>\n",
       "      <td>1724.470566</td>\n",
       "      <td>1572.100662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>1241.296035</td>\n",
       "      <td>2140.469132</td>\n",
       "      <td>1737.109584</td>\n",
       "      <td>1698.732479</td>\n",
       "      <td>1393.658827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3</td>\n",
       "      <td>2107.370679</td>\n",
       "      <td>1706.699109</td>\n",
       "      <td>2663.519216</td>\n",
       "      <td>1362.375932</td>\n",
       "      <td>2288.358855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>874.3799</td>\n",
       "      <td>1822.800565</td>\n",
       "      <td>1801.221329</td>\n",
       "      <td>1379.822873</td>\n",
       "      <td>1360.70871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>1789.883085</td>\n",
       "      <td>1631.077291</td>\n",
       "      <td>2386.884995</td>\n",
       "      <td>1745.966703</td>\n",
       "      <td>1986.549472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1            2            3            4            5\n",
       "0     0   786.163332  1893.617989  1656.606032  1508.050258  1265.243842\n",
       "1     1  2036.162052  1216.147297  2521.655699  1644.656337    2072.8969\n",
       "2     0   948.560884  2171.532519  1861.113602  1777.445263  1569.230653\n",
       "3     3   1522.75006  1475.920741  2057.235609  1309.609253  1591.616548\n",
       "4     4  1548.300035  2092.940959  1342.575013  1792.842291  1041.100386\n",
       "...  ..          ...          ...          ...          ...          ...\n",
       "9995  4  1552.679681  2298.016194   2018.83842  1724.470566  1572.100662\n",
       "9996  0  1241.296035  2140.469132  1737.109584  1698.732479  1393.658827\n",
       "9997  3  2107.370679  1706.699109  2663.519216  1362.375932  2288.358855\n",
       "9998  0     874.3799  1822.800565  1801.221329  1379.822873   1360.70871\n",
       "9999  1  1789.883085  1631.077291  2386.884995  1745.966703  1986.549472\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc_score(y_test,y_pred, multi_class=\"ovo\")\n",
    "# score_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_frame.to_csv(r\"..\\data\\interim\\template_matching.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean confusion matrix\n",
      " [[295.4  17.4  10.   54.4  29.4]\n",
      " [  9.4 349.8   4.6  18.8   6.8]\n",
      " [  2.2   4.  260.2   4.4 129.4]\n",
      " [ 23.8  11.4   4.8 334.4  26.6]\n",
      " [ 80.4   8.6 126.8  30.2 156.8]]\n",
      "\n",
      "Variance of mean confusion matrix\n",
      " [[273.84   0.64   2.8   58.64  13.04]\n",
      " [  9.84 169.36   2.64  14.96   7.76]\n",
      " [  1.76   4.4  151.76   7.44  97.84]\n",
      " [ 52.56  12.64   2.56  41.84  13.84]\n",
      " [139.44   3.44 106.16  31.36 186.96]]\n"
     ]
    }
   ],
   "source": [
    "mean_conf_matrix = np.mean(collect,axis=0)\n",
    "var_conf_matrix = np.var(collect,axis=0)\n",
    "print(\"Mean confusion matrix\\n\", mean_conf_matrix)\n",
    "print()\n",
    "print(\"Variance of mean confusion matrix\\n\", var_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6983\n",
      "Std Accuracy: 0.0146\n",
      "\n",
      "Precision: [0.7184, 0.8941, 0.6404, 0.7565, 0.4489]\n",
      "Std Precision: [0.0313, 0.0051, 0.0257, 0.0122, 0.0283]\n",
      "\n",
      "Recall: [0.7265, 0.8984, 0.6506, 0.8344, 0.3892]\n",
      "Std Recall: [0.0061, 0.0082, 0.0236, 0.0226, 0.0198]\n",
      "\n",
      "F1: [0.7221, 0.8962, 0.6454, 0.7933, 0.4167]\n",
      "Std F1: [0.0175, 0.004, 0.0242, 0.0108, 0.0214]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\", round(np.mean([all_scores[i][0] for i in range(5)],axis=0),4))\n",
    "print(\"Std Accuracy:\", round(np.std([all_scores[i][0] for i in range(5)]),4))\n",
    "print()\n",
    "print(\"Precision:\",list(map(lambda x:round(x,4),np.mean([all_scores[i][1] for i in range(5)],axis=0))))\n",
    "print(\"Std Precision:\",list(map(lambda x:round(x,4),np.std([all_scores[i][1] for i in range(5)],axis=0))))\n",
    "print()\n",
    "print(\"Recall:\",list(map(lambda x:round(x,4),np.mean([all_scores[i][2] for i in range(5)],axis=0))))\n",
    "print(\"Std Recall:\",list(map(lambda x:round(x,4),np.std([all_scores[i][2] for i in range(5)],axis=0))))\n",
    "print()\n",
    "print(\"F1:\",list(map(lambda x:round(x,4),np.mean([all_scores[i][3] for i in range(5)],axis=0))))\n",
    "print(\"Std F1:\",list(map(lambda x:round(x,4),np.std([all_scores[i][3] for i in range(5)],axis=0))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the template matching by taking the mean and dividing it over the variance, measuring the distance from that. Either I have done it in a not intended way or it is just not a reliable way of predicting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Confusion Matrix:\n",
      " [[ 89   8 229  36  29]\n",
      " [ 52 227  18  91   9]\n",
      " [ 66   1 284  12  37]\n",
      " [ 89 126  74 101  22]\n",
      " [ 55   2 308  14  21]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       391\n",
      "           1       0.62      0.57      0.60       397\n",
      "           2       0.31      0.71      0.43       400\n",
      "           3       0.40      0.25      0.30       412\n",
      "           4       0.18      0.05      0.08       400\n",
      "\n",
      "    accuracy                           0.36      2000\n",
      "   macro avg       0.35      0.36      0.33      2000\n",
      "weighted avg       0.35      0.36      0.33      2000\n",
      "\n",
      "Fold 1:\n",
      "Confusion Matrix:\n",
      " [[ 89  14 238  35  33]\n",
      " [ 46 244  17 100   7]\n",
      " [ 77   0 285  11  16]\n",
      " [ 71 126  71 115  16]\n",
      " [ 52   4 302  11  20]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.22      0.24       409\n",
      "           1       0.63      0.59      0.61       414\n",
      "           2       0.31      0.73      0.44       389\n",
      "           3       0.42      0.29      0.34       399\n",
      "           4       0.22      0.05      0.08       389\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.38      0.34      2000\n",
      "weighted avg       0.37      0.38      0.34      2000\n",
      "\n",
      "Fold 2:\n",
      "Confusion Matrix:\n",
      " [[ 85  11 222  42  32]\n",
      " [ 46 221  18  94   5]\n",
      " [ 69   0 310  16  16]\n",
      " [ 60 130  77 109  16]\n",
      " [ 36   1 336  24  24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.22      0.25       392\n",
      "           1       0.61      0.58      0.59       384\n",
      "           2       0.32      0.75      0.45       411\n",
      "           3       0.38      0.28      0.32       392\n",
      "           4       0.26      0.06      0.09       421\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.37      0.38      0.34      2000\n",
      "weighted avg       0.37      0.37      0.34      2000\n",
      "\n",
      "Fold 3:\n",
      "Confusion Matrix:\n",
      " [[ 97  11 236  35  34]\n",
      " [ 48 202  23  82   3]\n",
      " [ 62   0 297  22  11]\n",
      " [ 78 122  76 106  15]\n",
      " [ 52   5 344  19  20]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.23      0.26       413\n",
      "           1       0.59      0.56      0.58       358\n",
      "           2       0.30      0.76      0.43       392\n",
      "           3       0.40      0.27      0.32       397\n",
      "           4       0.24      0.05      0.08       440\n",
      "\n",
      "    accuracy                           0.36      2000\n",
      "   macro avg       0.37      0.37      0.33      2000\n",
      "weighted avg       0.36      0.36      0.32      2000\n",
      "\n",
      "Fold 4:\n",
      "Confusion Matrix:\n",
      " [[ 77  16 250  52  33]\n",
      " [ 43 218  20 106   7]\n",
      " [ 61   1 316  14  17]\n",
      " [ 57 131  71 129  17]\n",
      " [ 44   6 273  16  25]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.18      0.22       428\n",
      "           1       0.59      0.55      0.57       394\n",
      "           2       0.34      0.77      0.47       409\n",
      "           3       0.41      0.32      0.36       405\n",
      "           4       0.25      0.07      0.11       364\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.38      0.34      2000\n",
      "weighted avg       0.37      0.38      0.35      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_col_name(row):    \n",
    "    b = (results_df.loc[row.name] == row['Template_score'])\n",
    "    return b.index[b.argmax()]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(data_raw)\n",
    "collect = []\n",
    "\n",
    "for i,(train_index, test_index) in enumerate(kf.split(data_raw)):\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    clothes = data_raw[train_index]\n",
    "    test_clothes = data_raw[test_index]\n",
    "    mean_clothes = [np.mean(clothes[clothes[:,-1]==x])/np.var(clothes[clothes[:,-1]==x]) for x in range(5)]\n",
    "\n",
    "    test_results = pd.DataFrame(test_index)\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(mean_clothes)-1,-1,-1):\n",
    "        results = abs(np.mean(test_clothes,axis=1)/np.var(test_clothes,axis=1)-mean_clothes[i])\n",
    "        results_df.insert(0,i,pd.Series(results).values,allow_duplicates=True)\n",
    "    \n",
    "    test_results['Actual_score'] = test_clothes[:,-1]\n",
    "    test_results.insert(2,\"Template_score\",results_df.min(axis = 1))\n",
    "    test_results['Template_score'] = test_results.apply(get_col_name, axis=1)\n",
    "                 \n",
    "    y_test = test_results['Actual_score']\n",
    "    y_pred = test_results['Template_score']\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report:\\n',classification_report(y_test, y_pred))\n",
    "    \n",
    "    collect.append(confusion_matrix(y_test, y_pred))\n",
    "allones = np.array(collect).sum(axis=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
