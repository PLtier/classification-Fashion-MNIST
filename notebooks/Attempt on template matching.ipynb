{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load(r\"c:\\Users\\wenze\\Documents\\02_Courses\\3S_AW_24\\ML\\MLProject2024\\fashion_train.npy\")\n",
    "data_img = [np.reshape(image[:784],(28,28)) for image in data_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the template matching with the averaged out templates for each category.\n",
    "Results are surprisingly good, given that the model is pretty straightforward in the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Confusion Matrix:\n",
      " [[296  18  13  54  22]\n",
      " [ 11 328   4  22   5]\n",
      " [  1   5 274   5 122]\n",
      " [ 31  25   1 326  40]\n",
      " [ 85  11 128  26 147]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       403\n",
      "           1       0.85      0.89      0.87       370\n",
      "           2       0.65      0.67      0.66       407\n",
      "           3       0.75      0.77      0.76       423\n",
      "           4       0.44      0.37      0.40       397\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.68      0.69      0.68      2000\n",
      "weighted avg       0.68      0.69      0.68      2000\n",
      "\n",
      "Fold 1:\n",
      "Confusion Matrix:\n",
      " [[315  17   7  54  37]\n",
      " [  6 335   2  16  10]\n",
      " [  2   1 281   5 121]\n",
      " [ 19   7   2 334  23]\n",
      " [ 77   8 139  29 153]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       430\n",
      "           1       0.91      0.91      0.91       369\n",
      "           2       0.65      0.69      0.67       410\n",
      "           3       0.76      0.87      0.81       385\n",
      "           4       0.44      0.38      0.41       406\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.70      0.71      0.71      2000\n",
      "weighted avg       0.70      0.71      0.70      2000\n",
      "\n",
      "Fold 2:\n",
      "Confusion Matrix:\n",
      " [[299  21  11  52  31]\n",
      " [  9 346   4  17   7]\n",
      " [  2   4 257   3 152]\n",
      " [ 19   7   7 329  28]\n",
      " [ 76  13 119  26 161]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       414\n",
      "           1       0.88      0.90      0.89       383\n",
      "           2       0.65      0.61      0.63       418\n",
      "           3       0.77      0.84      0.81       390\n",
      "           4       0.42      0.41      0.42       395\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.69      0.70      0.70      2000\n",
      "weighted avg       0.69      0.70      0.69      2000\n",
      "\n",
      "Fold 3:\n",
      "Confusion Matrix:\n",
      " [[265  17  10  64  26]\n",
      " [  7 361   6  20   9]\n",
      " [  1   4 273   5 105]\n",
      " [ 18  11   6 345  20]\n",
      " [ 85   9 131  35 167]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70       382\n",
      "           1       0.90      0.90      0.90       403\n",
      "           2       0.64      0.70      0.67       388\n",
      "           3       0.74      0.86      0.79       400\n",
      "           4       0.51      0.39      0.44       427\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.70      0.71      0.70      2000\n",
      "weighted avg       0.70      0.71      0.70      2000\n",
      "\n",
      "Fold 4:\n",
      "Confusion Matrix:\n",
      " [[303  14  12  46  29]\n",
      " [ 13 380   6  17   6]\n",
      " [  5   5 220   5 143]\n",
      " [ 26   8   7 341  25]\n",
      " [ 75   6 116  31 161]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       404\n",
      "           1       0.92      0.90      0.91       422\n",
      "           2       0.61      0.58      0.60       378\n",
      "           3       0.78      0.84      0.81       407\n",
      "           4       0.44      0.41      0.43       389\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.69      0.70      0.69      2000\n",
      "weighted avg       0.70      0.70      0.70      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_col_name(row):    \n",
    "    b = (results_df.loc[row.name] == row['Template_score'])\n",
    "    return b.index[b.argmax()]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(data_raw)\n",
    "collect = []\n",
    "\n",
    "for i,(train_index, test_index) in enumerate(kf.split(data_raw)):\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    clothes = data_raw[train_index]\n",
    "    test_clothes = data_raw[test_index]\n",
    "    mean_clothes = [np.mean(clothes[clothes[:,-1]==x],axis=0) for x in range(5)]\n",
    "\n",
    "    test_results = pd.DataFrame(test_index)\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(mean_clothes)-1,-1,-1):\n",
    "        results = np.sqrt(np.sum(np.square((test_clothes-mean_clothes[i])),axis=1))\n",
    "        results_df.insert(0,i,pd.Series(results).values,allow_duplicates=True)\n",
    "    \n",
    "    test_results['Actual_score'] = test_clothes[:,-1]\n",
    "    test_results.insert(2,\"Template_score\",results_df.min(axis = 1))\n",
    "    test_results['Template_score'] = test_results.apply(get_col_name, axis=1)\n",
    "                 \n",
    "    y_test = test_results['Actual_score']\n",
    "    y_pred = test_results['Template_score']\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report:\\n',classification_report(y_test, y_pred))\n",
    "    \n",
    "    collect.append(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the template matching by taking the mean and dividing it over the variance, measuring the distance from that. Either I have done it in a not intended way or it is just not a reliable way of predicting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Confusion Matrix:\n",
      " [[ 94  10 232  37  28]\n",
      " [ 51 233  20 100   6]\n",
      " [ 69   1 280  15  20]\n",
      " [ 79 130  77  96  20]\n",
      " [ 46   4 309  13  30]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.23      0.25       401\n",
      "           1       0.62      0.57      0.59       410\n",
      "           2       0.31      0.73      0.43       385\n",
      "           3       0.37      0.24      0.29       402\n",
      "           4       0.29      0.07      0.12       402\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.37      0.37      0.34      2000\n",
      "weighted avg       0.37      0.37      0.34      2000\n",
      "\n",
      "Fold 1:\n",
      "Confusion Matrix:\n",
      " [[ 88  13 227  37  44]\n",
      " [ 43 207  19  80   1]\n",
      " [ 63   0 323  21  20]\n",
      " [ 72 122  78 104  12]\n",
      " [ 33   2 350  22  19]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.22      0.25       409\n",
      "           1       0.60      0.59      0.60       350\n",
      "           2       0.32      0.76      0.45       427\n",
      "           3       0.39      0.27      0.32       388\n",
      "           4       0.20      0.04      0.07       426\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.36      0.38      0.34      2000\n",
      "weighted avg       0.35      0.37      0.33      2000\n",
      "\n",
      "Fold 2:\n",
      "Confusion Matrix:\n",
      " [[ 81  10 244  48  28]\n",
      " [ 54 232  12  98   7]\n",
      " [ 54   0 301  12  16]\n",
      " [ 68 118  75 123  18]\n",
      " [ 44   5 309  22  21]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.20      0.23       411\n",
      "           1       0.64      0.58      0.60       403\n",
      "           2       0.32      0.79      0.45       383\n",
      "           3       0.41      0.31      0.35       402\n",
      "           4       0.23      0.05      0.09       401\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.38      0.34      2000\n",
      "weighted avg       0.37      0.38      0.34      2000\n",
      "\n",
      "Fold 3:\n",
      "Confusion Matrix:\n",
      " [[ 82  19 248  34  28]\n",
      " [ 46 206  22  95   7]\n",
      " [ 67   1 324  10  21]\n",
      " [ 63 133  65 123  18]\n",
      " [ 50   4 306  14  14]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.20      0.23       411\n",
      "           1       0.57      0.55      0.56       376\n",
      "           2       0.34      0.77      0.47       423\n",
      "           3       0.45      0.31      0.36       402\n",
      "           4       0.16      0.04      0.06       388\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.35      0.37      0.33      2000\n",
      "weighted avg       0.35      0.37      0.33      2000\n",
      "\n",
      "Fold 4:\n",
      "Confusion Matrix:\n",
      " [[ 93   9 227  43  29]\n",
      " [ 36 231  23 109   9]\n",
      " [ 82   0 265  16  20]\n",
      " [ 73 129  70 120  19]\n",
      " [ 62   2 291  17  25]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.23      0.25       401\n",
      "           1       0.62      0.57      0.59       408\n",
      "           2       0.30      0.69      0.42       383\n",
      "           3       0.39      0.29      0.34       411\n",
      "           4       0.25      0.06      0.10       397\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.37      0.37      0.34      2000\n",
      "weighted avg       0.37      0.37      0.34      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_col_name(row):    \n",
    "    b = (results_df.loc[row.name] == row['Template_score'])\n",
    "    return b.index[b.argmax()]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(data_raw)\n",
    "collect = []\n",
    "\n",
    "for i,(train_index, test_index) in enumerate(kf.split(data_raw)):\n",
    "    \n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    clothes = data_raw[train_index]\n",
    "    test_clothes = data_raw[test_index]\n",
    "    mean_clothes = [np.mean(clothes[clothes[:,-1]==x])/np.var(clothes[clothes[:,-1]==x]) for x in range(5)]\n",
    "\n",
    "    test_results = pd.DataFrame(test_index)\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(mean_clothes)-1,-1,-1):\n",
    "        results = abs(np.mean(test_clothes,axis=1)/np.var(test_clothes,axis=1)-mean_clothes[i])\n",
    "        results_df.insert(0,i,pd.Series(results).values,allow_duplicates=True)\n",
    "    \n",
    "    test_results['Actual_score'] = test_clothes[:,-1]\n",
    "    test_results.insert(2,\"Template_score\",results_df.min(axis = 1))\n",
    "    test_results['Template_score'] = test_results.apply(get_col_name, axis=1)\n",
    "                 \n",
    "    y_test = test_results['Actual_score']\n",
    "    y_pred = test_results['Template_score']\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report:\\n',classification_report(y_test, y_pred))\n",
    "    \n",
    "    collect.append(confusion_matrix(y_test, y_pred))\n",
    "allones = np.array(collect).sum(axis=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
